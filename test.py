import yt_dlp
import time
import json
from pathlib import Path
from typing import List, Optional, Set
import random
import hashlib

class ChannelSubtitleDownloader:
    def __init__(self, proxy_list: Optional[List[str]] = None, output_dir: str = "subtitles", archive_file: str = "downloaded_archive.txt", cookies_file: Optional[str] = None):
        """
        Kanal bazlÄ± altyazÄ± indirici
        
        Args:
            proxy_list: Proxy listesi (Ã¶rn: ['http://user:pass@ip:port'])
            output_dir: AltyazÄ±larÄ±n kaydedileceÄŸi klasÃ¶r
            archive_file: Ä°ndirilen videolarÄ±n ID'lerinin tutulduÄŸu dosya
            cookies_file: YouTube cookies dosyasÄ± (Netscape formatÄ±)
        """
        self.proxy_list = proxy_list or []
        self.current_proxy_index = 0
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.archive_file = Path(archive_file)
        self.cookies_file = Path(cookies_file) if cookies_file else None
        self.failed_proxies = set()
        self.download_count = 0
        self.proxy_rotation_threshold = 3
        
        # Cookies dosyasÄ± kontrolÃ¼
        if self.cookies_file and not self.cookies_file.exists():
            print(f"âš ï¸ UyarÄ±: Cookies dosyasÄ± bulunamadÄ±: {self.cookies_file}")
            print("ğŸ’¡ YaÅŸ kÄ±sÄ±tlamalÄ± videolar iÃ§in cookies gereklidir")
        
        # Archive dosyasÄ±nÄ± oluÅŸtur
        if not self.archive_file.exists():
            self.archive_file.touch()
    
    def load_downloaded_ids(self) -> Set[str]:
        """Ä°ndirilen video ID'lerini yÃ¼kle"""
        if self.archive_file.exists():
            with open(self.archive_file, 'r', encoding='utf-8') as f:
                return set(line.strip() for line in f if line.strip())
        return set()
    
    def save_downloaded_id(self, video_id: str):
        """Ä°ndirilen video ID'sini kaydet"""
        with open(self.archive_file, 'a', encoding='utf-8') as f:
            f.write(f"{video_id}\n")
    
    def get_next_proxy(self) -> Optional[str]:
        """Bir sonraki kullanÄ±labilir proxy'yi dÃ¶ndÃ¼r"""
        if not self.proxy_list:
            return None
            
        available_proxies = [p for p in self.proxy_list if p not in self.failed_proxies]
        
        if not available_proxies:
            print("âš ï¸ TÃ¼m proxy'ler baÅŸarÄ±sÄ±z oldu, baÅŸarÄ±sÄ±z listeyi sÄ±fÄ±rlÄ±yorum...")
            self.failed_proxies.clear()
            available_proxies = self.proxy_list
            
        self.current_proxy_index = (self.current_proxy_index + 1) % len(available_proxies)
        return available_proxies[self.current_proxy_index]
    
    def get_ydl_opts(self, proxy: Optional[str] = None, for_listing: bool = False) -> dict:
        """yt-dlp ayarlarÄ±nÄ± oluÅŸtur"""
        opts = {
            'quiet': False,
            'no_warnings': False,
            'extract_flat': for_listing,
            'socket_timeout': 30,
            'retries': 10,
            'fragment_retries': 10,
            'file_access_retries': 5,
            'ignoreerrors': True,
            # YouTube rate limit bypass ayarlarÄ±
            'extractor_args': {
                'youtube': {
                    'player_client': ['android', 'web'],  # Android client kullan
                    'skip': ['dash', 'hls']  # Gereksiz formatlarÄ± atla
                }
            },
            # User agent deÄŸiÅŸtir (bot tespitini engelle)
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-us,en;q=0.5',
                'Sec-Fetch-Mode': 'navigate',
            },
        }
        
        # Cookies ekle (varsa)
        if self.cookies_file and self.cookies_file.exists():
            opts['cookiefile'] = str(self.cookies_file)
        
        if not for_listing:
            # AltyazÄ± indirme iÃ§in ek ayarlar
            opts.update({
                'skip_download': True,
                'writesubtitles': True,
                'writeautomaticsub': True,
                'subtitleslangs': ['tr', 'en'],
                'subtitlesformat': 'srt/best',
                'outtmpl': str(self.output_dir / '%(channel)s/%(title)s [%(id)s].%(ext)s'),
                'ratelimit': None,
                'throttledratelimit': None,
                'concurrent_fragment_downloads': 5,
            })
        
        if proxy:
            opts['proxy'] = proxy
            
        return opts
    
    def get_channel_videos(self, channel_identifier: str, max_videos: int = 30, sort_by: str = 'date') -> List[dict]:
        """
        Kanaldan son N videoyu Ã§ek
        
        Args:
            channel_identifier: Kanal adÄ± veya URL
            max_videos: Ã‡ekilecek maksimum video sayÄ±sÄ±
            sort_by: SÄ±ralama tÃ¼rÃ¼ ('date' = en yeni, 'popular' = en popÃ¼ler)
        """
        print(f"\nğŸ” Kanal videolarÄ± taranÄ±yor: {channel_identifier}")
        print(f"ğŸ“Š Maksimum video sayÄ±sÄ±: {max_videos}")
        print(f"ğŸ”¢ SÄ±ralama: {sort_by}")
        
        # Kanal URL'ini oluÅŸtur
        if channel_identifier.startswith('http'):
            channel_url = channel_identifier
        elif channel_identifier.startswith('@'):
            channel_url = f"https://www.youtube.com/{channel_identifier}/videos"
        else:
            channel_url = f"https://www.youtube.com/@{channel_identifier}/videos"
        
        # SÄ±ralama parametresi ekle
        if sort_by == 'date':
            channel_url += "?sort=dd"  # Sort by date (newest first)
        elif sort_by == 'popular':
            channel_url += "?sort=p"   # Sort by popularity
        
        proxy = self.get_next_proxy() if self.proxy_list else None
        ydl_opts = self.get_ydl_opts(proxy=proxy, for_listing=True)
        ydl_opts['playlistend'] = max_videos  # Ä°lk N videoyu al (en yeni olan N video)
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                print(f"ğŸŒ URL: {channel_url}")
                if proxy:
                    print(f"ğŸ”„ Proxy: {proxy}")
                
                info = ydl.extract_info(channel_url, download=False)
                
                if not info:
                    print("âŒ Kanal bilgisi alÄ±namadÄ±")
                    return []
                
                entries = info.get('entries', [])
                videos = []
                
                for entry in entries[:max_videos]:
                    if entry:
                        video_info = {
                            'id': entry.get('id'),
                            'title': entry.get('title'),
                            'url': entry.get('url') or f"https://www.youtube.com/watch?v={entry.get('id')}",
                            'channel': info.get('channel') or info.get('uploader'),
                        }
                        videos.append(video_info)
                
                print(f"âœ… {len(videos)} video bulundu")
                return videos
                
        except Exception as e:
            print(f"âŒ Kanal videolarÄ± alÄ±nÄ±rken hata: {e}")
            return []
    
    def download_subtitles(self, video_info: dict, max_retries: int = 5) -> bool:
        """Tek bir videonun altyazÄ±larÄ±nÄ± indir"""
        video_id = video_info['id']
        url = video_info['url']
        
        # Daha Ã¶nce indirilmiÅŸ mi kontrol et
        downloaded_ids = self.load_downloaded_ids()
        if video_id in downloaded_ids:
            print(f"â­ï¸ AtlanÄ±yor (zaten indirilmiÅŸ): {video_info['title']}")
            return True
        
        retries = 0
        last_error = None
        
        while retries < max_retries:
            try:
                # Ã–NEMLI: Ä°lk denemeden itibaren proxy kullan
                proxy = None
                if self.proxy_list:
                    proxy = self.get_next_proxy()
                
                ydl_opts = self.get_ydl_opts(proxy)
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    print(f"\nğŸ“¥ Ä°ndiriliyor: {video_info['title']}")
                    print(f"ğŸ†” Video ID: {video_id}")
                    if proxy:
                        print(f"ğŸ”„ KullanÄ±lan Proxy: {proxy[:30]}...")  # Sadece ilk 30 karakter (gÃ¼venlik)
                    
                    info = ydl.extract_info(url, download=True)
                    
                    if info:
                        # BaÅŸarÄ±lÄ± indirmeyi kaydet
                        self.save_downloaded_id(video_id)
                        print(f"âœ… BaÅŸarÄ±lÄ±: {video_info['title']}")
                        self.download_count += 1
                        return True
                        
            except yt_dlp.utils.DownloadError as e:
                error_msg = str(e).lower()
                last_error = str(e)
                
                # 429 veya rate limit tespiti
                if '429' in error_msg or 'too many requests' in error_msg or 'throttl' in error_msg or 'rate limit' in error_msg:
                    print(f"âš ï¸ Rate Limit Tespit Edildi! (Deneme {retries + 1}/{max_retries})")
                    
                    if self.proxy_list:
                        if proxy:
                            print(f"âŒ Proxy baÅŸarÄ±sÄ±z olarak iÅŸaretlendi: {proxy[:30]}...")
                            self.failed_proxies.add(proxy)
                        
                        # Yeni proxy al ve tekrar dene
                        retries += 1
                        wait_time = min(5 * (retries), 30)  # Exponential backoff (max 30 saniye)
                        print(f"â³ {wait_time} saniye bekleyip farklÄ± proxy ile tekrar denenecek...")
                        time.sleep(wait_time)
                        continue
                    else:
                        # Proxy yoksa uzun bekle
                        print("âš ï¸ Proxy bulunamadÄ±! Uzun bekleme gerekiyor...")
                        wait_time = 60 * (retries + 1)  # 60, 120, 180 saniye...
                        print(f"â³ {wait_time} saniye bekleniyor...")
                        time.sleep(wait_time)
                        retries += 1
                        continue
                else:
                    print(f"âŒ Hata: {e}")
                    retries += 1
                    time.sleep(random.uniform(2, 5))
                    
            except Exception as e:
                last_error = str(e)
                print(f"âŒ Beklenmeyen hata: {e}")
                retries += 1
                time.sleep(random.uniform(2, 5))
        
        print(f"ğŸ’” BaÅŸarÄ±sÄ±z (maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±): {video_info['title']}")
        if last_error:
            print(f"ğŸ“ Son hata: {last_error}")
        return False
    
    def process_channel(self, channel_identifier: str, max_videos: int = 30, delay_between: tuple = (2, 5)):
        """Bir kanalÄ±n videolarÄ±nÄ± iÅŸle"""
        print(f"\n{'='*70}")
        print(f"ğŸ“º KANAL Ä°ÅLENÄ°YOR: {channel_identifier}")
        print(f"{'='*70}")
        
        # VideolarÄ± al
        videos = self.get_channel_videos(channel_identifier, max_videos)
        
        if not videos:
            print("âš ï¸ Video bulunamadÄ± veya kanal eriÅŸilemedi")
            return
        
        # Ä°ndirme istatistikleri
        total = len(videos)
        successful = 0
        skipped = 0
        failed = 0
        
        print(f"\nğŸš€ {total} video iÃ§in altyazÄ± indirme baÅŸlÄ±yor...")
        
        for idx, video in enumerate(videos, 1):
            print(f"\n{'='*70}")
            print(f"Ä°lerleme: {idx}/{total}")
            print(f"{'='*70}")
            
            # Daha Ã¶nce indirilmiÅŸ mi kontrol et
            downloaded_ids = self.load_downloaded_ids()
            if video['id'] in downloaded_ids:
                skipped += 1
                print(f"â­ï¸ AtlanÄ±yor (zaten indirilmiÅŸ): {video['title']}")
            else:
                if self.download_subtitles(video):
                    successful += 1
                else:
                    failed += 1
            
            # Son video deÄŸilse bekle
            if idx < total:
                wait_time = random.uniform(*delay_between)
                print(f"â±ï¸ Sonraki video iÃ§in {wait_time:.1f} saniye bekleniyor...")
                time.sleep(wait_time)
        
        # Ã–zet
        print(f"\n{'='*70}")
        print(f"ğŸ“Š KANAL Ã–ZET: {channel_identifier}")
        print(f"{'='*70}")
        print(f"âœ… Yeni indirilen: {successful}/{total}")
        print(f"â­ï¸ AtlandÄ± (zaten var): {skipped}/{total}")
        print(f"âŒ BaÅŸarÄ±sÄ±z: {failed}/{total}")
        print(f"ğŸ“ KlasÃ¶r: {self.output_dir.absolute()}")
    
    def process_channels(self, channels: List[str], max_videos_per_channel: int = 30, delay_between_videos: tuple = (2, 5), delay_between_channels: tuple = (5, 10)):
        """Birden fazla kanalÄ± iÅŸle"""
        total_channels = len(channels)
        
        print(f"\n{'#'*70}")
        print(f"ğŸ¬ TOPLU KANAL Ä°ÅLEME BAÅLIYOR")
        print(f"{'#'*70}")
        print(f"ğŸ“º Toplam kanal sayÄ±sÄ±: {total_channels}")
        print(f"ğŸ“Š Her kanaldan maksimum video: {max_videos_per_channel}")
        print(f"ğŸ“ Ã‡Ä±ktÄ± klasÃ¶rÃ¼: {self.output_dir.absolute()}")
        print(f"ğŸ’¾ Archive dosyasÄ±: {self.archive_file.absolute()}")
        
        for idx, channel in enumerate(channels, 1):
            print(f"\n\n{'#'*70}")
            print(f"KANAL {idx}/{total_channels}")
            print(f"{'#'*70}")
            
            self.process_channel(channel, max_videos_per_channel, delay_between_videos)
            
            # Son kanal deÄŸilse bekle
            if idx < total_channels:
                wait_time = random.uniform(*delay_between_channels)
                print(f"\nâ±ï¸ Sonraki kanal iÃ§in {wait_time:.1f} saniye bekleniyor...\n")
                time.sleep(wait_time)
        
        # Genel Ã¶zet
        print(f"\n\n{'#'*70}")
        print(f"ğŸ‰ TÃœM KANALLAR Ä°ÅLENDÄ°")
        print(f"{'#'*70}")
        print(f"âœ… Toplam iÅŸlenen kanal: {total_channels}")
        print(f"ğŸ“ AltyazÄ±lar: {self.output_dir.absolute()}")
        print(f"ğŸ’¾ Archive: {self.archive_file.absolute()}")


# KULLANIM Ã–RNEÄÄ°
if __name__ == "__main__":
    # Proxy listesi
    proxies = [
        # 'http://kullanici1:sifre123@192.168.1.100:8080',
        # 'http://kullanici2:sifre456@192.168.1.101:8080',
        # 'http://kullanici3:sifre789@192.168.1.102:8080',
    ]
    
    # Ä°ÅŸlenecek kanallar
    # Format: '@kanaladi' veya 'kanaladi' veya tam URL
    channels = [
        '@TEDx',
        '@Fireship',
        '@ThePrimeTimeagen',
        # Daha fazla kanal ekleyin...
    ]
    
    # Ä°ndiriciyi baÅŸlat
    downloader = ChannelSubtitleDownloader(
        proxy_list=proxies if proxies else None,
        output_dir="subtitles",
        archive_file="downloaded_archive.txt",
        cookies_file="youtube_cookies.txt"  # Opsiyonel: YaÅŸ kÄ±sÄ±tlamalÄ± videolar iÃ§in
    )
    
    # KanallarÄ± iÅŸle
    downloader.process_channels(
        channels=channels,
        max_videos_per_channel=30,  # Her kanaldan son 30 video
        delay_between_videos=(2, 5),  # Videolar arasÄ± bekleme
        delay_between_channels=(5, 10)  # Kanallar arasÄ± bekleme
    )
    
    # TEK BÄ°R KANAL Ä°Ã‡Ä°N KULLANIM:
    # downloader.process_channel('@kanaladi', max_videos=30)